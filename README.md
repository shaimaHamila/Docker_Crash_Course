# Why Docker

With Docker, developers can build any app in any language using any toolchain. “Dockerized” apps are completely portable and can run anywhere - colleagues’ OS X and Windows laptops, QA servers running Ubuntu in the cloud, and production data center VMs running Red Hat.

# What is Docker?

Docker is a set of platform-as-a-service products that use OS-level virtualization to deliver software in packages called containers.

Docker is **a software platform that allows you to build, test, and deploy applications quickly**.

# What is a Container?

A container is like a box or a package that contains everything that our application needs to run, including dependencies, source code, the correct runtime environment, libraries, system tools, versions, and more. Docker is a tool for managing containers.

# Containers VS VMs

The key differentiator between containers and virtual machines is that virtual machines virtualize an entire machine down to the hardware layers, and containers only virtualize software layers above the operating system level.

### VM

Has its own full operating system and is typically slower.

### Containers

Share the host’s operating system and are typically quicker.

# Install Docker

To install Docker, follow the instructions for your operating system on the official [Docker website](https://www.docker.com/get-started).

# Docker Images

**Images are like blueprints for containers. They are read-only.**

A running container uses an isolated filesystem provided by an image. The image contains everything needed to run an application - dependencies, configurations, scripts, binaries, etc. The image also contains other configurations for the container, such as environment variables, a default command to run, and other metadata.

Images are made up of several “Layers” where each layer essentially adds something else to the image incrementally. Typically, we start with a parent image as the first layer in our image, describing the operating system and the runtime environment of the container that we want.

You can get the parent image from Docker Hub: **repository of Docker images**

# Dockerfile

Docker can build images automatically by reading instructions from a Dockerfile. A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. It includes instructions to specify a parent image, the working directory, copy source files, run commands, expose ports, and more.

1. Specify a parent image
2. Specify the working directory of the image
3. Copy package.json
4. Run the npm install command at the build time to add all the dependencies to the image
5. Copy over all the source files
6. Expose port
7. Specify a command that should be run only when the container based on this image
8. Build the image

### Example of Dockerfile:

```docker
# This docker file is like a set of instructions which tells docker how to build our image with all of its different layers.
FROM node:latest

WORKDIR /app

RUN npm install -g nodemon

# This for caching the npm install command
COPY package.json .

# To install the dependencies into the image we run npm install
# We're allowed to specify commands that we want to run our image
# To specify a command we use the keyword RUN
RUN npm install

# Copy some files to the image
# The first dot is a relative path to the diractory i want to copy my source files from (current diractory in our case .)(can be ./src)
# the second dot is the path inside the image where i want to copy my source code to (The images have their own folder structure)( . root diractory and it is /app in our case coz we set it in the workdir)
COPY . .


# Tells docker which port the container should expose
EXPOSE 5000

# REMEBER the image is not a running application it's just a blueprint for a container

# The container is the thing that actually runs our application
# The container is a running instance of the image

# CMD allows as to specify a command that should be run at runtime when the container begins to run
CMD ["nodemon", "run", "dev"]

# To build the image we run the command docker build -t <name of the image> <path to the docker file>
# the -t flag is used to tag the image with a name
```

### Instructions

.dockerignore

FROM sets the Base Image for subsequent instructions.

RUN executes any commands in a new layer on top of the current image and commits the results.

CMD provides defaults for an executing container.

EXPOSE informs Docker that the container listens on the specified network ports at runtime.

COPY copies new files or directories to the container.

WORKDIR sets the working directory.

ENV sets environment variables.

ENTRYPOINT configures a container that will run as an executable.

### Volumes

Volumes are the preferred mechanism for persisting data generated by and used by Docker containers. They allow changes made in code to be reflected in the container.

# Docker Compose

Docker Compose is a tool for defining and running multi-container Docker applications. It allows you to define all your services, networks, and volumes in a single docker-compose.yml file.

Example of Docker Compose:

```docker
version: "3.8"
services:
  api:
    build: ./api
    container_name: api_c
    ports:
      - "5000:5000"
    volumes:
      - ./api:/app
      - /app/node_modules
  myblog:
    build: ./myblog
    container_name: myblog_c
    ports:
      - "3000:3000"
    stdin_open: true
    tty: true
    volumes:
      - ./myblog:/app # This volume is related to the myblog service
      - /app/node_modules
```

This example defines two services, api and myblog, each with its own configuration, and they can communicate with each other.

To start it, run the command:
`bach  docker-compose up `

To stop the project, run the command:
`bach  docker-compose down `

## Docker Commands, Help & Tips

Gist: Docker Commands, Help & Tips
